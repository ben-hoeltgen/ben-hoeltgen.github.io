---
title: "DeDUCE: Generating Counterfactual Explanations Efficiently"
collection: publications
category: workshops
permalink: /publication/2021-neurips-deduce
excerpt: 'An algorithm for generating counterfactual explanations. My second master thesis.'
date: 2021-10-01
venue: 'NeurIPS Worksho: Explainable AI Approaches for Debugging and Diagnosis'
# slidesurl: 'http://academicpages.github.io/files/slides1.pdf'
# paperurl: 'http://academicpages.github.io/files/paper1.pdf'
# bibtexurl: 'http://academicpages.github.io/files/bibtex1.bib'
citation: '<b>HÃ¶ltgen, B.</b>, Schut, L., Brauner, J., Gal, Y.: &quot;DeDUCE: Generating counterfactual explanations efficiently.&quot; <i>NeurIPS Worksho: Explainable AI Approaches for Debugging and Diagnosis</i>. 2021.'
---
### Abstract:
When an image classifier outputs a wrong class label, it can be helpful to see what changes in the image would lead to a correct classification. This is the aim of algorithms generating counterfactual explanations. However, there is no easily scalable method to generate such counterfactuals. We develop a new algorithm providing counterfactual explanations for large image classifiers trained with spectral normalisation at low computational cost. We empirically compare this algorithm against baselines from the literature; our novel algorithm consistently finds counterfactuals that are much closer to the original inputs. At the same time, the realism of these counterfactuals is comparable to the baselines.

[**PDF**](https://arxiv.org/pdf/2111.15639)

So many options,

so much potential, hiding

in calibration.

