---
title: "Causal modelling without introducing counterfactuals or abstract distributions"
collection: publications
category: in-progress
permalink: /publication/2024-icml-causality
excerpt: 'A different way of modelling causal inference.'
date: 2024-10-01
# venue: 'NeurIPS Worksho: Explainable AI Approaches for Debugging and Diagnosis'
# slidesurl: 'http://academicpages.github.io/files/slides1.pdf'
# paperurl: 'http://academicpages.github.io/files/paper1.pdf'
# bibtexurl: 'http://academicpages.github.io/files/bibtex1.bib'
citation: '<b>HÃ¶ltgen, B.</b>, Williamson, R.C.: &quot;Causal modelling without introducing counterfactuals or abstract distributions.&quot; <i>ICML Workshop: Humans, Algorithmic Decision-Making and Society</i>. 2024.'
---
### Abstract:
When an image classifier outputs a wrong class label, it can be helpful to see what changes in the image would lead to a correct classification. This is the aim of algorithms generating counterfactual explanations. However, there is no easily scalable method to generate such counterfactuals. We develop a new algorithm providing counterfactual explanations for large image classifiers trained with spectral normalisation at low computational cost. We empirically compare this algorithm against baselines from the literature; our novel algorithm consistently finds counterfactuals that are much closer to the original inputs. At the same time, the realism of these counterfactuals is comparable to the baselines.

[**preprint**](https://arxiv.org/pdf/2407.17385)

So many options,

so much potential, hiding

in calibration.

